{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4f8bbe",
   "metadata": {},
   "source": [
    "# Phase 5: Digital Exclusion Risk Scoring\n",
    "\n",
    "## Objective\n",
    "Quantify digital exclusion risk at the district-month level.\n",
    "\n",
    "**Digital Exclusion Definition:**\n",
    "> \"Aadhaar exists, but digital usability is limited due to poor mobile linkage and demographic constraints.\"\n",
    "\n",
    "## Input Files\n",
    "- `data/processed/district_features.csv` (from Phase 2)\n",
    "- `data/final/migration_intensity.csv` (from Phase 3)\n",
    "\n",
    "## Output File\n",
    "- `data/final/digital_exclusion_risk.csv`\n",
    "\n",
    "## Risk Score Components\n",
    "| Component | Weight | Source |\n",
    "|-----------|--------|--------|\n",
    "| Digital Gap | 0.5 | Phase 2 - digital_gap |\n",
    "| Demographic Risk | 0.3 | 1 - youth_ratio |\n",
    "| Migration Instability | 0.2 | ABS(migration_score) |\n",
    "\n",
    "## Risk Level Buckets\n",
    "| Score Range | Risk Level |\n",
    "|-------------|------------|\n",
    "| 70-100 | High |\n",
    "| 40-69 | Medium |\n",
    "| 0-39 | Low |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa5412",
   "metadata": {},
   "source": [
    "## Cell 1: Import Libraries and Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import Required Libraries\n",
    "-------------------------\n",
    "- pandas: Data manipulation\n",
    "- pathlib: Cross-platform file path handling\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define project paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "# Input files\n",
    "FEATURES_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"district_features.csv\"\n",
    "MIGRATION_PATH = PROJECT_ROOT / \"data\" / \"final\" / \"migration_intensity.csv\"\n",
    "\n",
    "# Output file\n",
    "OUTPUT_PATH = PROJECT_ROOT / \"data\" / \"final\" / \"digital_exclusion_risk.csv\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Libraries imported\")\n",
    "print(f\"ðŸ“‚ Features Input: {FEATURES_PATH}\")\n",
    "print(f\"ðŸ“‚ Migration Input: {MIGRATION_PATH}\")\n",
    "print(f\"ðŸ“‚ Output: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e17811",
   "metadata": {},
   "source": [
    "## Cell 2: Load Input Data from Phase 2 and Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7709603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load Input Data\n",
    "---------------\n",
    "1. district_features.csv (Phase 2): Contains digital_gap, youth_ratio\n",
    "2. migration_intensity.csv (Phase 3): Contains migration_score\n",
    "\n",
    "Both files are keyed by district_id and month.\n",
    "\"\"\"\n",
    "\n",
    "# Load Phase 2 features (digital_gap, youth_ratio)\n",
    "df_features = pd.read_csv(FEATURES_PATH)\n",
    "print(f\"âœ… Loaded {len(df_features):,} rows from Phase 2 (district_features.csv)\")\n",
    "print(f\"   Columns: {list(df_features.columns)}\")\n",
    "\n",
    "# Load Phase 3 migration scores\n",
    "df_migration = pd.read_csv(MIGRATION_PATH)\n",
    "print(f\"\\nâœ… Loaded {len(df_migration):,} rows from Phase 3 (migration_intensity.csv)\")\n",
    "print(f\"   Columns: {list(df_migration.columns)}\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nðŸ“‹ Sample features data:\")\n",
    "display(df_features[['district_id', 'month', 'youth_ratio', 'digital_gap']].head())\n",
    "\n",
    "print(f\"\\nðŸ“‹ Sample migration data:\")\n",
    "display(df_migration.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3220af4",
   "metadata": {},
   "source": [
    "## Cell 3: Merge Input Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92059a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge Input Datasets\n",
    "--------------------\n",
    "Combine Phase 2 features with Phase 3 migration scores.\n",
    "Join on district_id and month (the composite key).\n",
    "\"\"\"\n",
    "\n",
    "# Select only the columns we need from each dataset\n",
    "features_cols = ['district_id', 'month', 'youth_ratio', 'digital_gap']\n",
    "migration_cols = ['district_id', 'month', 'migration_score']\n",
    "\n",
    "# Merge on district_id and month\n",
    "df = pd.merge(\n",
    "    df_features[features_cols],\n",
    "    df_migration[migration_cols],\n",
    "    on=['district_id', 'month'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"âœ… Merged datasets: {len(df):,} rows\")\n",
    "print(f\"   Districts: {df['district_id'].nunique()}\")\n",
    "print(f\"   Months: {df['month'].nunique()}\")\n",
    "\n",
    "# Verify no missing values after merge\n",
    "missing = df.isna().sum().sum()\n",
    "if missing == 0:\n",
    "    print(f\"âœ… No missing values after merge\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Warning: {missing} missing values found\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Merged data sample:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022a97d",
   "metadata": {},
   "source": [
    "## Cell 4: Compute Risk Components\n",
    "\n",
    "**Three interpretable components:**\n",
    "\n",
    "1. **Digital Gap Component (weight: 0.5)**\n",
    "   - Directly from Phase 2: `digital_gap`\n",
    "   - Higher values = more digital exclusion\n",
    "\n",
    "2. **Demographic Risk Component (weight: 0.3)**\n",
    "   - Formula: `1 - youth_ratio`\n",
    "   - Lower youth population = higher demographic risk\n",
    "\n",
    "3. **Migration Instability Component (weight: 0.2)**\n",
    "   - Formula: `ABS(migration_score)`\n",
    "   - Both high inflow and outflow create instability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute Risk Components\n",
    "-----------------------\n",
    "Each component represents a different dimension of digital exclusion risk.\n",
    "\n",
    "1. digital_gap: Direct measure of mobile vs address update disparity\n",
    "   - Higher values indicate poor mobile linkage relative to address updates\n",
    "\n",
    "2. demographic_risk: Inverse of youth ratio\n",
    "   - Older populations tend to have lower digital literacy\n",
    "   - Formula: 1 - youth_ratio\n",
    "\n",
    "3. migration_instability: Absolute value of migration score\n",
    "   - Both high inflow and outflow create service delivery challenges\n",
    "   - Unstable populations face higher digital exclusion risk\n",
    "\"\"\"\n",
    "\n",
    "# Component 1: Digital Gap (directly from Phase 2)\n",
    "# Already normalized between 0 and 1\n",
    "df['digital_gap_component'] = df['digital_gap']\n",
    "\n",
    "# Component 2: Demographic Risk = 1 - youth_ratio\n",
    "# Lower youth ratio means older population with higher digital risk\n",
    "df['demographic_risk'] = 1 - df['youth_ratio']\n",
    "\n",
    "# Component 3: Migration Instability = ABS(migration_score)\n",
    "# Both extreme inflow and outflow create instability\n",
    "df['migration_instability'] = df['migration_score'].abs()\n",
    "\n",
    "print(f\"âœ… Risk components computed\")\n",
    "print(f\"\\nðŸ“Š Component statistics:\")\n",
    "print(f\"   digital_gap_component: min={df['digital_gap_component'].min():.4f}, max={df['digital_gap_component'].max():.4f}\")\n",
    "print(f\"   demographic_risk: min={df['demographic_risk'].min():.4f}, max={df['demographic_risk'].max():.4f}\")\n",
    "print(f\"   migration_instability: min={df['migration_instability'].min():.4f}, max={df['migration_instability'].max():.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Sample with components:\")\n",
    "df[['district_id', 'month', 'digital_gap_component', 'demographic_risk', 'migration_instability']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75fa30",
   "metadata": {},
   "source": [
    "## Cell 5: Compute Digital Exclusion Score\n",
    "\n",
    "**Formula:**\n",
    "```\n",
    "raw_risk = 0.5 * digital_gap + 0.3 * demographic_risk + 0.2 * migration_instability\n",
    "digital_exclusion_score = ROUND(MIN(1, raw_risk) * 100)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4cfb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute Digital Exclusion Score\n",
    "--------------------------------\n",
    "Weighted combination of three risk components:\n",
    "- Digital Gap: 50% weight (primary driver)\n",
    "- Demographic Risk: 30% weight (population structure)\n",
    "- Migration Instability: 20% weight (stability factor)\n",
    "\n",
    "Final score is normalized to 0-100 scale as an integer.\n",
    "\"\"\"\n",
    "\n",
    "# Define weights (must sum to 1.0)\n",
    "WEIGHT_DIGITAL_GAP = 0.5\n",
    "WEIGHT_DEMOGRAPHIC = 0.3\n",
    "WEIGHT_MIGRATION = 0.2\n",
    "\n",
    "# Compute raw risk score (weighted sum)\n",
    "df['raw_risk'] = (\n",
    "    WEIGHT_DIGITAL_GAP * df['digital_gap_component'] +\n",
    "    WEIGHT_DEMOGRAPHIC * df['demographic_risk'] +\n",
    "    WEIGHT_MIGRATION * df['migration_instability']\n",
    ")\n",
    "\n",
    "# Clamp raw_risk to [0, 1] and scale to 0-100\n",
    "# Formula: ROUND(MIN(1, raw_risk) * 100)\n",
    "df['digital_exclusion_score'] = (\n",
    "    df['raw_risk']\n",
    "    .clip(lower=0, upper=1)  # Clamp to [0, 1]\n",
    "    .mul(100)                 # Scale to 0-100\n",
    "    .round()                  # Round to nearest integer\n",
    "    .astype(int)              # Convert to integer\n",
    ")\n",
    "\n",
    "print(f\"âœ… Digital exclusion scores computed\")\n",
    "print(f\"\\nðŸ“Š Score statistics:\")\n",
    "print(f\"   Min: {df['digital_exclusion_score'].min()}\")\n",
    "print(f\"   Max: {df['digital_exclusion_score'].max()}\")\n",
    "print(f\"   Mean: {df['digital_exclusion_score'].mean():.1f}\")\n",
    "print(f\"   Median: {df['digital_exclusion_score'].median():.0f}\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Sample scores:\")\n",
    "df[['district_id', 'month', 'raw_risk', 'digital_exclusion_score']].head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab88acb",
   "metadata": {},
   "source": [
    "## Cell 6: Assign Risk Level Categories\n",
    "\n",
    "**Risk Level Buckets:**\n",
    "| Score Range | Risk Level |\n",
    "|-------------|------------|\n",
    "| 70-100 | High |\n",
    "| 40-69 | Medium |\n",
    "| 0-39 | Low |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assign Risk Level Categories\n",
    "----------------------------\n",
    "Categorize digital_exclusion_score into three risk levels:\n",
    "\n",
    "- High (70-100): Critical digital exclusion, needs immediate intervention\n",
    "- Medium (40-69): Moderate risk, requires monitoring\n",
    "- Low (0-39): Acceptable digital inclusion levels\n",
    "\"\"\"\n",
    "\n",
    "def assign_risk_level(score: int) -> str:\n",
    "    \"\"\"\n",
    "    Assign risk level based on digital exclusion score.\n",
    "    \n",
    "    Args:\n",
    "        score: Integer score from 0-100\n",
    "    \n",
    "    Returns:\n",
    "        One of: 'High', 'Medium', 'Low'\n",
    "    \"\"\"\n",
    "    if score >= 70:\n",
    "        return \"High\"\n",
    "    elif score >= 40:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# Apply risk level assignment\n",
    "df['risk_level'] = df['digital_exclusion_score'].apply(assign_risk_level)\n",
    "\n",
    "print(f\"âœ… Risk levels assigned\")\n",
    "print(f\"\\nðŸ“Š Risk level distribution:\")\n",
    "risk_dist = df['risk_level'].value_counts().sort_index()\n",
    "for level in ['High', 'Low', 'Medium']:  # Alphabetical order\n",
    "    if level in risk_dist.index:\n",
    "        count = risk_dist[level]\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"   {level}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Mean score by risk level:\")\n",
    "print(df.groupby('risk_level')['digital_exclusion_score'].mean().round(1))\n",
    "\n",
    "print(f\"\\nðŸ“‹ Sample with risk levels:\")\n",
    "df[['district_id', 'month', 'digital_exclusion_score', 'risk_level']].head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84c19f",
   "metadata": {},
   "source": [
    "## Cell 7: Prepare Final Output Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare Final Output\n",
    "--------------------\n",
    "Select only the required columns in the exact schema order.\n",
    "\n",
    "Output Schema:\n",
    "- district_id (string)\n",
    "- month (string, YYYY-MM)\n",
    "- digital_exclusion_score (integer, 0-100)\n",
    "- risk_level (string: High, Medium, Low)\n",
    "\"\"\"\n",
    "\n",
    "# Define exact output schema\n",
    "OUTPUT_COLUMNS = [\n",
    "    'district_id',\n",
    "    'month',\n",
    "    'digital_exclusion_score',\n",
    "    'risk_level'\n",
    "]\n",
    "\n",
    "# Select only required columns\n",
    "df_output = df[OUTPUT_COLUMNS].copy()\n",
    "\n",
    "# Sort by district_id and month for deterministic output\n",
    "df_output = df_output.sort_values(['district_id', 'month']).reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… Final output prepared: {len(df_output):,} rows\")\n",
    "print(f\"\\nðŸ“Š Columns: {list(df_output.columns)}\")\n",
    "print(f\"\\nðŸ“‹ Data types:\")\n",
    "print(df_output.dtypes)\n",
    "print(f\"\\nðŸ“‹ First 12 rows:\")\n",
    "df_output.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62821f88",
   "metadata": {},
   "source": [
    "## Cell 8: Data Quality Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc771296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Quality Checks\n",
    "-------------------\n",
    "Validate all required constraints before export.\n",
    "\"\"\"\n",
    "\n",
    "checks_passed = 0\n",
    "total_checks = 7\n",
    "\n",
    "# Check 1: No NaN values\n",
    "nan_count = df_output.isna().sum().sum()\n",
    "if nan_count == 0:\n",
    "    print(\"âœ… Check 1: No NaN values\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"âŒ Check 1: Found {nan_count} NaN values\")\n",
    "\n",
    "# Check 2: digital_exclusion_score is integer\n",
    "if df_output['digital_exclusion_score'].dtype in ['int64', 'int32', 'int']:\n",
    "    print(\"âœ… Check 2: digital_exclusion_score is integer type\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"âŒ Check 2: digital_exclusion_score is {df_output['digital_exclusion_score'].dtype}, expected integer\")\n",
    "\n",
    "# Check 3: digital_exclusion_score is between 0 and 100\n",
    "score_min = df_output['digital_exclusion_score'].min()\n",
    "score_max = df_output['digital_exclusion_score'].max()\n",
    "if score_min >= 0 and score_max <= 100:\n",
    "    print(f\"âœ… Check 3: digital_exclusion_score in range [0, 100] (actual: {score_min}-{score_max})\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"âŒ Check 3: digital_exclusion_score out of range [{score_min}, {score_max}]\")\n",
    "\n",
    "# Check 4: Valid risk_level values\n",
    "valid_levels = {'High', 'Medium', 'Low'}\n",
    "actual_levels = set(df_output['risk_level'].unique())\n",
    "if actual_levels.issubset(valid_levels):\n",
    "    print(f\"âœ… Check 4: Valid risk_level values: {actual_levels}\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"âŒ Check 4: Invalid risk_level found: {actual_levels - valid_levels}\")\n",
    "\n",
    "# Check 5: risk_level is non-null\n",
    "if df_output['risk_level'].notna().all():\n",
    "    print(\"âœ… Check 5: risk_level is non-null\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(\"âŒ Check 5: risk_level has null values\")\n",
    "\n",
    "# Check 6: Correct column count (exactly 4)\n",
    "if len(df_output.columns) == 4:\n",
    "    print(\"âœ… Check 6: Exactly 4 columns (no extra columns)\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"âŒ Check 6: Expected 4 columns, got {len(df_output.columns)}\")\n",
    "\n",
    "# Check 7: One row per district-month (no duplicates)\n",
    "duplicates = df_output.duplicated(subset=['district_id', 'month']).sum()\n",
    "if duplicates == 0:\n",
    "    print(f\"âœ… Check 7: No duplicate district-month combinations\")\n",
    "    checks_passed += 1\n",
    "else:\n",
    "    print(f\"âŒ Check 7: Found {duplicates} duplicate district-month rows\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "if checks_passed == total_checks:\n",
    "    print(f\"âœ… ALL {total_checks} VALIDATION CHECKS PASSED\")\n",
    "else:\n",
    "    print(f\"âš ï¸ {checks_passed}/{total_checks} checks passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d8cb7",
   "metadata": {},
   "source": [
    "## Cell 9: Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015fdcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Export to CSV\n",
    "-------------\n",
    "Save the digital exclusion risk data in CSV format.\n",
    "\"\"\"\n",
    "\n",
    "# Export to CSV (no index column)\n",
    "df_output.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"âœ… CSV exported to: {OUTPUT_PATH}\")\n",
    "print(f\"\\nðŸ“Š Export Summary:\")\n",
    "print(f\"   Total rows: {len(df_output):,}\")\n",
    "print(f\"   Districts: {df_output['district_id'].nunique()}\")\n",
    "print(f\"   Months: {df_output['month'].nunique()}\")\n",
    "print(f\"\\nðŸ“Š Risk level distribution:\")\n",
    "for level in ['High', 'Medium', 'Low']:\n",
    "    count = (df_output['risk_level'] == level).sum()\n",
    "    pct = count / len(df_output) * 100\n",
    "    print(f\"   {level}: {count} ({pct:.1f}%)\")\n",
    "print(f\"\\nðŸ“‹ Schema:\")\n",
    "for col in df_output.columns:\n",
    "    sample_val = df_output[col].iloc[0]\n",
    "    print(f\"   {col}: {df_output[col].dtype} (e.g., {sample_val})\")\n",
    "print(f\"\\nðŸ“„ First 10 rows:\")\n",
    "df_output.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb04682",
   "metadata": {},
   "source": [
    "## Phase 5 Complete\n",
    "\n",
    "### Output File\n",
    "`data/final/digital_exclusion_risk.csv`\n",
    "\n",
    "### Schema\n",
    "| Field | Type | Description |\n",
    "|-------|------|-------------|\n",
    "| district_id | string | District identifier |\n",
    "| month | string | YYYY-MM format |\n",
    "| digital_exclusion_score | integer | Risk score (0-100) |\n",
    "| risk_level | string | High, Medium, or Low |\n",
    "\n",
    "### Risk Score Formula\n",
    "```\n",
    "raw_risk = 0.5 * digital_gap + 0.3 * (1 - youth_ratio) + 0.2 * ABS(migration_score)\n",
    "digital_exclusion_score = ROUND(MIN(1, raw_risk) * 100)\n",
    "```\n",
    "\n",
    "### Risk Level Buckets\n",
    "- **High** (70-100): Critical digital exclusion\n",
    "- **Medium** (40-69): Moderate risk\n",
    "- **Low** (0-39): Acceptable inclusion\n",
    "\n",
    "### Next Steps\n",
    "All ML phase outputs are now ready for backend API integration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
